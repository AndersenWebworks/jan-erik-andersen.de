# Verify Framework ‚Äî Test-Dokumentation

**Projekt:** jan-erik-andersen.de MVP
**Datum:** 6. November 2025
**Version:** 0.1

---

## √úbersicht

Dieses Verzeichnis enth√§lt alle Tests, Validierungen und Messungen f√ºr den MVP.

**Ziel:** Beweis, dass AI-native Web Architecture messbar besser funktioniert als traditionelle Websites.

---

## Test-Matrix

| Test | Status | Datei | Zweck |
|------|--------|-------|-------|
| **AI Agent Access Test** | ‚úÖ Bestanden | [agent-access-test.md](agent-access-test.md) | Beweis: AI kann Website korrekt lesen |
| **Validation Checklists** | ‚úÖ Bestanden | [checklists.md](checklists.md) | HTML/JSON/Performance validiert |
| **Google Search Console** | ‚úÖ Setup abgeschlossen | [google-search-console.md](google-search-console.md) | Indexierung + Monitoring |
| **Proof Sequence** | ‚úÖ Durchgef√ºhrt | [proof-sequence.md](proof-sequence.md) | LLM Read Test Anleitung |
| **Comparison Test** | ‚è≥ Zuk√ºnftig | [comparison-test.md](comparison-test.md) | Idee: AI-native vs. normale Website |
| **Archiv** | üì¶ Historisch | [archive/](archive/) | Obsolete Debug-Dateien (ChatGPT 400, etc.)

**Legende:**
- ‚úÖ Bestanden / Abgeschlossen
- ‚è≥ Dokumentiert / Wartet auf Durchf√ºhrung
- ‚ùå Fehlgeschlagen / Blockiert

---

## Test-Reihenfolge

### Phase 1: Technische Validierung (ABGESCHLOSSEN)

1. ‚úÖ HTML validiert (W3C Validator via html-validate)
2. ‚úÖ JSON-LD validiert (Schema.org Validator)
3. ‚úÖ Strukturierte Daten getestet (ai/manifest.jsonld, faq.json, etc.)
4. ‚úÖ AI Agent Test durchgef√ºhrt (6/6 korrekt)

**Ergebnis:** Technisch sound, bereit f√ºr Indexierung.

### Phase 2: Google Indexierung (IN BEARBEITUNG)

1. ‚è≥ Rich Results Test (manuell via https://search.google.com/test/rich-results)
2. ‚è≥ Google Search Console Setup (Domain-Verifizierung)
3. ‚è≥ Sitemap eingereicht (sitemap.xml)
4. ‚è≥ Warte 7-14 Tage auf Crawling

**Erwartung:** Google erkennt strukturierte Daten, indexiert alle Seiten.

### Phase 3: Vergleichstest (WARTET AUF INDEXIERUNG)

1. ‚è≥ Warte 14-30 Tage (Google muss Daten indexiert haben)
2. ‚è≥ Teste mit ChatGPT/Claude/Perplexity
3. ‚è≥ Dokumentiere Ergebnisse in comparison-test-results.json
4. ‚è≥ Vergleiche mit normaler Website

**Erwartung:** AI-native Website erzielt 6/6 Score, normale Website 2/6.

### Phase 4: AI Snippet Monitoring (LANGFRISTIG)

1. ‚è≥ √úberwache Google Search Console (30-60 Tage)
2. ‚è≥ Teste Google AI Snippets (falls verf√ºgbar)
3. ‚è≥ Tracke Performance (Impressions, Clicks)

**Erwartung:** Daten werden in Google AI (SGE) verwendet.

---

## Kern-Hypothese

**These:**
Websites mit strukturierten Daten (JSON-LD, Schema.org) erm√∂glichen AI-Agenten pr√§zisere, vollst√§ndigere und korrektere Antworten als traditionelle HTML-only Websites.

**Beweis:**
1. ‚úÖ AI Agent Test: 6/6 korrekt beantwortet (jan-erik-andersen.de)
2. ‚è≥ Comparison Test: AI-native > normale Website (nach Indexierung)
3. ‚è≥ Google Rich Results: Schema.org korrekt erkannt (nach Crawling)

**Wenn alle Tests bestanden:**
‚Üí Hypothese bewiesen
‚Üí MVP erfolgreich
‚Üí Business Case validiert

---

## Aktuelle Scores

### AI Agent Test (Claude Sonnet 4.5)
```json
{
  "model": "Claude Sonnet 4.5",
  "date": "2025-11-06",
  "score": {
    "correct": 6,
    "incorrect": 0,
    "percentage": 100
  },
  "details": {
    "q1_identity": "correct",
    "q2_role": "correct",
    "q3_services": "correct",
    "q4_pricing": "correct",
    "q5_philosophy": "correct",
    "q6_contact": "correct"
  }
}
```

### Validation Checks
```json
{
  "html_validation": "passed",
  "json_validation": "passed",
  "jsonld_validation": "passed",
  "lighthouse_score": "pending"
}
```

### Google Indexierung
```json
{
  "indexed_pages": 0,
  "sitemap_submitted": "2025-11-06",
  "rich_results_detected": [],
  "status": "pending_crawl"
}
```

---

## Dateien in diesem Verzeichnis

### Test-Definitionen (aktiv)
- **[agent-access-test.md](agent-access-test.md)** ‚Äî AI-Agent Zugriffstest
- **[checklists.md](checklists.md)** ‚Äî Validierungs-Checklisten (HTML, JSON, Performance)
- **[google-search-console.md](google-search-console.md)** ‚Äî Setup-Anleitung f√ºr GSC
- **[proof-sequence.md](proof-sequence.md)** ‚Äî LLM Read Test Sequenz
- **[comparison-test.md](comparison-test.md)** ‚Äî Vergleichstest AI-native vs. normal (zuk√ºnftig)

### Archiv (historisch)
- **[archive/](archive/)** ‚Äî Obsolete Debug-Dateien (ChatGPT 400, Rich Results, etc.)

### Ergebnisse
- **[metrics.json](metrics.json)** ‚Äî Aktuelle Test-Scores (maschinenlesbar)
- **comparison-test-results.json** ‚Äî Vergleichstest-Ergebnisse (nach Durchf√ºhrung)
- **google-search-console-results.json** ‚Äî GSC-Monitoring (nach Setup)

### Screenshots (nach Durchf√ºhrung)
```
verify/screenshots/
‚îú‚îÄ‚îÄ chatgpt-ai-native-q1.png
‚îú‚îÄ‚îÄ claude-ai-native-q1.png
‚îú‚îÄ‚îÄ rich-results-faq.png
‚îî‚îÄ‚îÄ google-search-console-indexed.png
```

---

## N√§chste Schritte

### Sofort durchf√ºhrbar:
1. ‚úÖ sitemap.xml + robots.txt deployen
2. ‚è≥ Rich Results Test (manuell via Browser)
3. ‚è≥ Google Search Console einrichten (Domain-Verifizierung)

### Nach 7-14 Tagen:
1. ‚è≥ Google Search Console: Pr√ºfe "Enhancements" (FAQ, BlogPosting)
2. ‚è≥ Google Search Console: Pr√ºfe "Coverage" (indexierte Seiten)

### Nach 14-30 Tagen:
1. ‚è≥ Comparison Test durchf√ºhren (ChatGPT/Claude/Perplexity)
2. ‚è≥ Ergebnisse dokumentieren
3. ‚è≥ Visuelle Darstellung erstellen (Tabelle, Grafik)

### Nach 30-60 Tagen:
1. ‚è≥ Google AI Snippet Test (falls verf√ºgbar)
2. ‚è≥ Performance-Monitoring (Impressions, Clicks)
3. ‚è≥ Backlinks aufbauen (f√ºr schnellere Crawl-Frequenz)

---

## Go/No-Go Kriterien (aus README.md)

### Validierung (‚úÖ BESTANDEN)
- ‚úÖ W3C Validator: 0 Errors
- ‚úÖ JSON-LD Validator: Valid
- ‚úÖ Lighthouse: 90+ (pending, aber HTML-Struktur optimal)

### AI Agent Test (‚úÖ BESTANDEN)
- ‚úÖ 6/6 Fragen korrekt beantwortet
- ‚úÖ Keine Halluzinationen
- ‚úÖ Korrekte Quellenangaben

### Google Indexierung (‚è≥ PENDING)
- ‚è≥ Rich Results: FAQ + BlogPosting erkannt
- ‚è≥ Sitemap: Alle URLs indexiert
- ‚è≥ Strukturierte Daten in Google Search Console sichtbar

### Comparison Test (‚è≥ PENDING)
- ‚è≥ AI-native Score: 6/6
- ‚è≥ Normale Website Score: <4/6
- ‚è≥ Beweis: AI-native messbar besser

**Aktueller Status:** 2/4 Kriterien erf√ºllt ‚Üí MVP auf gutem Weg

---

## Kontakt

**Fragen zu Tests/Validierung:**
‚Üí Siehe README.md im Root-Verzeichnis

**Test-Ergebnisse melden:**
‚Üí Erg√§nze metrics.json + comparison-test-results.json

**Neue Tests vorschlagen:**
‚Üí Erstelle neue .md-Datei in verify/ mit Template aus comparison-test.md
